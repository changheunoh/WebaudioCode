<!doctype html>
<html>
<head>
	<meta charset="utf-8">
	<title> my Audio Visualization </title>
</head>
<body>
	<h1> Mini Project #1: Pitch Tracking </h1>

	<p><canvas id='spec_view' style="background: white;"></canvas></p>

	<script>
	var context;
	var myAudioBuffer = null;
	var analyser;

	var spec_view;
	var WIDTH = 640;
	var HEIGHT = 320;


	// initial setting for pitch detection
	var PITCH_MIN = 36;
	var PITCH_MAX = 96;
	var PITCH_STEP = 0.25;
	var pitch_range = [];
	var pitch_range_hz = [];
	var NUM_HARMONICS = 15;

	//my variables
	var pitchgram = [];
	var energygram = [];
	var combfilter = [];
	var sumfilter = [];
	var maximumIndex = 0;
	var myharmonicity = 0;
	var binfrqs = [];
	var samplingFrequency = 1;

	window.onload=function(){
		console.log("window.onload")
		// canvas
		spec_view = document.getElementById("spec_view");
		spec_view.width =  WIDTH;
		spec_view.height = HEIGHT;

		// create audio context
		context = new AudioContext();

		// analyser
	    analyser = context.createAnalyser();
	    analyser.fftSize = 2048;
			analyser.smoothingTimeConstant = 0;

		// pitch range of interest
		for (var pitch = PITCH_MIN; pitch <= PITCH_MAX; pitch = pitch + PITCH_STEP)
		{
			pitch_range.push(pitch);
			pitch_range_hz.push(midi2hertz(pitch))
		}

		// define some templates

		samplingFrequency = context.sampleRate;

		binfrqs = new Float32Array(analyser.frequencyBinCount);
		for (var ii = 0; ii<analyser.frequencyBinCount;ii++){
				binfrqs[ii] = ii*samplingFrequency/analyser.frequencyBinCount/2;
		}
		combfilter = new Array(pitch_range.length);
		sumfilter = new Array(pitch_range.length);
		for (ii=0; ii<pitch_range.length;ii++){
			var temp_frq = pitch_range_hz[ii];
			combfilter[ii]= new Float32Array(analyser.frequencyBinCount);
			sumfilter[ii]= new Float32Array(analyser.frequencyBinCount);

			for (var jj=0; jj<analyser.frequencyBinCount; jj++){
				var theta = 2*Math.PI*binfrqs[jj]/temp_frq;
				if((binfrqs[jj] > NUM_HARMONICS*temp_frq)||(binfrqs[jj] < temp_frq/2)){
						combfilter[ii][jj] = 0;
						sumfilter[ii][jj] = 0;
				}
				else{
					combfilter[ii][jj] = 0.5*Math.cos(theta) + 0.5;
					sumfilter[ii][jj] = 1;
				}
			}
		}
		console.log("window.onload-end")
	}

	function midi2hertz(midi) {
		var hertz;
		///// YOUR CODE IS HERE /////

		//power(2,(midi-69)/12)*440;
		//exponent = (midi-69)/12;
		hertz = 440*Math.pow(2, (midi-69)/12);

		/////////////////////////////
		return hertz;
	}

	function draw_spec() {
		// 2d canvas context
		var drawContext = spec_view.getContext('2d');

		// fill rectangular
		drawContext.fillStyle = 'rgb(200, 200, 200)';
		drawContext.fillRect(0, 0, WIDTH, HEIGHT);

		// drawing line setting
		drawContext.lineWidth = 2;
		drawContext.strokeStyle = 'rgb(0, 0, 0)';
		drawContext.beginPath();

		// get samples
		var dataArray = new Float32Array(analyser.frequencyBinCount);
		analyser.getFloatFrequencyData(dataArray);

		var freq_scale = 10;
		var sliceWidth = WIDTH * 1.0 / (dataArray.length/freq_scale);
		var x = 0;

		// display spectrum up to Nyquist_Frequency/10
		for (var i = 0; i < dataArray.length/freq_scale; i++) {
	        var v = (dataArray[i] + 100)/50;
	        var y = HEIGHT - v * HEIGHT/2;

	    	if(i === 0) {
	        	drawContext.moveTo(x, y);
	        } else {
	        	drawContext.lineTo(x, y);
	        }

	        x += sliceWidth;
		}

		// last touch
		drawContext.lineTo(draw_spec.width, draw_spec.height/2);
		drawContext.stroke();

		//
		// pitch detection
		//
		// Refer to the stft_pitch.m file (MATLAB) to implement the pitch detection algorithm

		///// YOUR CODE IS HERE /////
		pitchgram = new Float32Array(analyser.frequencyBinCount);
		energygram = new Float32Array(analyser.frequencyBinCount);

		for (ii=0; ii<pitch_range.length; ii++){
			pitchgram[ii] = 0;
			for(jj=0; jj<analyser.frequencyBinCount; jj++){
				pitchgram[ii] = pitchgram[ii] + combfilter[ii][jj]*Math.pow(10, (dataArray[jj]/20));
				energygram[ii] = energygram[ii] + sumfilter[ii][jj]*Math.pow(10, (dataArray[jj]/20));
			}
			if(pitchgram[ii]>= pitchgram[maximumIndex]){
					maximumIndex = ii;
			}
		}

		myharmonicity = pitchgram[maximumIndex]/energygram[maximumIndex];

		/////////////////////////////

		drawContext.font = "30px Arial";
		if ( myharmonicity > 0.6 )  // THIS SHOULD BE REPLACED WITH THE CONDITIONS FOR HARMONICITY AND ENERGY VALUES
		{

			var detected_pitch = Math.round(pitch_range_hz[maximumIndex]);   // THIS SHOULD BE REPLACED WITH DETECTED PITCH FROM THE CODE ABOVE
			var detected_pitch_position = 40;   // THIS SHOULD BE REPLACED WITH DETECTED PITCH FROM THE CODE ABOVE

			detected_pitch_position = sliceWidth * detected_pitch * analyser.frequencyBinCount / (samplingFrequency/2);

			drawContext.strokeText(detected_pitch+" Hz",100,50);

			var detected_midi = Math.round(pitch_range[maximumIndex]);
			drawContext.strokeText(detected_midi+" midi",100,100);

			drawContext.fillStyle = 'rgb(100,0,0)';
			drawContext.fillRect(detected_pitch_position, 0, 2, HEIGHT);
		}

		// queue for next callback
		window.requestAnimationFrame(draw_spec);
	}



	if (!navigator.getUserMedia)
		navigator.getUserMedia = (navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia);

	if (!navigator.getUserMedia)
		alert("Error: getUserMedia not supported!");

	// get audio input streaming
	navigator.getUserMedia({audio: true}, onStream, onStreamError)

	// successCallback
	function onStream(stream) {
	    var input = context.createMediaStreamSource(stream);

		// Connect graph
		input.connect(analyser);

		// visualize audio
		draw_spec();
	}

	// errorCallback
	function onStreamError(error) {
		console.error('Error getting microphone', error);
	}

	</script>
</body>
</html>
